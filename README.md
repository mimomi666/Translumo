[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Github All Releases](https://img.shields.io/github/downloads/ramjke/Translumo/total.svg)]()

<p align="center">
  <img width="670" src="https://github.com/ramjke/Translumo/assets/29047281/8985049f-ea1c-428e-94be-042ece66cb54">
</p>
  <h2 align="center" style="border: 0">Advanced Real-Time Screen Translator</h2>

<p align="center"><strong>English</strong> | <a href="docs/README-RU.md"><strong>Ğ ÑƒÑÑĞºĞ¸Ğ¹</strong></a></p>

## ğŸ”¥ Fork Notice | åˆ†æ”¯è¯´æ˜

This is a **fork** of the original [Translumo repository](https://github.com/ramjke/Translumo) with **enhanced multimodal translation capabilities**.

**Original Repository**: https://github.com/ramjke/Translumo

### âœ¨ What's New in This Fork | æœ¬åˆ†æ”¯çš„æ–°åŠŸèƒ½

This fork adds **Multimodal AI Translation** support, allowing Translumo to use advanced AI models (GPT-4o, GPT-4 Vision, Claude 3, etc.) to translate images directly without OCR. This provides:

- **Higher accuracy** for complex layouts and stylized text
- **Direct image translation** without OCR preprocessing
- **Support for any OpenAI-compatible vision API**
- **Customizable prompts** for better translation control

æœ¬åˆ†æ”¯æ–°å¢äº†**å¤šæ¨¡æ€ AI ç¿»è¯‘**æ”¯æŒï¼Œå…è®¸ Translumo ä½¿ç”¨å…ˆè¿›çš„ AI æ¨¡å‹ï¼ˆGPT-4oã€GPT-4 Visionã€Claude 3 ç­‰ï¼‰ç›´æ¥ç¿»è¯‘å›¾åƒï¼Œæ— éœ€ OCRã€‚è¿™å¸¦æ¥äº†ï¼š

- **æ›´é«˜çš„å‡†ç¡®æ€§**ï¼Œç‰¹åˆ«æ˜¯å¯¹äºå¤æ‚å¸ƒå±€å’Œé£æ ¼åŒ–æ–‡æœ¬
- **ç›´æ¥å›¾åƒç¿»è¯‘**ï¼Œæ— éœ€ OCR é¢„å¤„ç†
- **æ”¯æŒä»»ä½• OpenAI å…¼å®¹çš„è§†è§‰ API**
- **å¯è‡ªå®šä¹‰æç¤ºè¯**ï¼Œæ›´å¥½åœ°æ§åˆ¶ç¿»è¯‘æ•ˆæœ

ğŸ“– **See the [Multimodal Translation Tutorial](#multimodal-translation-tutorial) below for setup and usage guide.**

ğŸ“– **æŸ¥çœ‹ä¸‹æ–¹çš„[å¤šæ¨¡æ€ç¿»è¯‘æ•™ç¨‹](#multimodal-translation-tutorial)äº†è§£è®¾ç½®å’Œä½¿ç”¨æŒ‡å—ã€‚**


## Download Translumo

### ğŸ‰ Download This Fork with Multimodal Translation

**Latest release with multimodal support:**  
ğŸ‘‰ **[Download from Releases](https://github.com/mimomi666/Translumo/releases/latest)**

After downloading, unzip the archive and run `Translumo.exe`.

This fork includes all features from the original Translumo v1.0.2 plus **multimodal AI translation** support.

### Download Original Version

If you prefer the original version without multimodal features:  
[Translumo_1.0.2.zip](https://github.com/ramjke/Translumo/releases/download/v.1.0.2/Translumo_1.0.2.zip) (Original repository) 

## Main Features

- **High text recognition precision**  
  Translumo allows combining multiple OCR engines simultaneously. It uses a machine learning model to score each OCR result and selects the best one.  

  <p align="center">
    <img width="740" src="https://github.com/ramjke/Translumo/assets/29047281/649e5fab-a5de-4c54-a3d8-f7ea95b8f218">
  </p>

- **Game oriented**  
  Designed for real-time translation in PC games, but works anywhere on the screen with any application.

- **Low latency**  
  Several optimizations reduce system impact and minimize latency between text appearance and translation.

- **Integrated modern OCR engines**: Windows OCR (recommended), Tesseract 5.2 (legacy), EasyOCR (legacy)

- **Available translators**: DeepL (recommended), Google Translate, Yandex Translate, Naver Papago.

- **Supported recognition languages**: English, Russian, Japanese, Chinese (Simplified), Korean.

- **Supported translation languages**: English, Russian, Japanese, Chinese (Simplified), Korean, French, Spanish, German, Portuguese, Italian, Vietnamese, Thai, Turkish, Arabic, Greek, Brazilian Portuguese, Polish, Belarusian, Persian, Indonesian, Bulgarian, Czech, Danish, Estonian, Finnish, Hungarian, Lithuanian, Latvian, Dutch, Romanian, Slovak, Slovenian, Swedish, Ukrainian.

## System Requirements

### Minimal requirements to use Tesseract and Windows OCR
- Windows 10 version 2004 (build 19041) or later, or Windows 11
- DirectX 11 compatible GPU
- 2 GB RAM

### Minimal requirements to use EasyOCR
- NVIDIA GPU with CUDA SDK 11.8 support (GTX 750, 8xxM, 9xx series or newer)
- 8 GB RAM
- At least 5 GB of free storage space

## How to Use

![Preview](https://github.com/ramjke/Translumo/blob/7f4a73ffba0e5a0090ea0bfc3d72acb99832a0f4/docs/preview-EN.gif)

1. Open the Settings (**Alt+G**)
2. Select languages: source language for OCR and translation language
3. Select text recognition engines (see Usage Tips for recommended modes)
4. Define the capture area: press **Alt+Q** and select an area on the screen
5. Run translation (press **~**)

### Recommended OCR Engines

- It is recommended to use **WindowsOCR** only.

Tesseract is old, slow, and produces many errors.  
EasyOCR is even slower, requires significant resources (including a specific GPU), and often leads to bugs.  

Itâ€™s probably better to remove all other OCR engines and keep only WindowsOCR, but they are still included in Translumo for historical reasons.

### Select Minimum Capture Area
Reducing the capture area decreases the chance of picking up random letters from the background. Larger frames take longer to process.

### Use Proxy List to Avoid Blocking by Translation Services
Some translators may block clients sending many requests. Configure personal or shared IPv4 proxies (1-2 is usually enough) under **Languages â†’ Proxy tab**. The app will alternate proxies to reduce requests from a single IP.

### Use Borderless or Windowed Modes in Games (Not Fullscreen)
These modes are required for correct translation overlay display. If your game does not support them, use tools like [Borderless Gaming](https://github.com/Codeusa/Borderless-Gaming).

## FAQ

**Q: I get "Failed to capture screen" or nothing happens after translation starts**  
A: Ensure the target window is active. Restart Translumo or reopen the target window if needed.

**Q: Borderless/windowed mode is set, but the translation window is under the game**  
A: With the game running and focused, press the hotkey (**Alt+T** by default) to hide and show the translation window.

**Q: EasyOCR package download failed**  
A: Try reinstalling while connected to a VPN.

**Q: Hotkeys don't work**  
A: Other applications may be intercepting hotkeys.

**Q: Text detection failed (TesseractOCREngine)**  
A: Ensure the application path contains only Latin letters.

## Multimodal Translation Tutorial

### ğŸŒŸ What is Multimodal Translation? | ä»€ä¹ˆæ˜¯å¤šæ¨¡æ€ç¿»è¯‘ï¼Ÿ

Multimodal translation uses AI models with vision capabilities (like GPT-4o, GPT-4 Vision, Claude 3) to translate text directly from images, bypassing traditional OCR entirely. This results in:

- Better handling of stylized fonts and complex layouts
- More accurate translations with context awareness
- Support for vertical text, overlapping text, and decorative elements
- Direct translation without text extraction errors

å¤šæ¨¡æ€ç¿»è¯‘ä½¿ç”¨å…·æœ‰è§†è§‰èƒ½åŠ›çš„ AI æ¨¡å‹ï¼ˆå¦‚ GPT-4oã€GPT-4 Visionã€Claude 3ï¼‰ç›´æ¥ä»å›¾åƒç¿»è¯‘æ–‡æœ¬ï¼Œå®Œå…¨ç»•è¿‡ä¼ ç»Ÿ OCRã€‚è¿™å¸¦æ¥äº†ï¼š

- æ›´å¥½åœ°å¤„ç†é£æ ¼åŒ–å­—ä½“å’Œå¤æ‚å¸ƒå±€
- å…·æœ‰ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„æ›´å‡†ç¡®ç¿»è¯‘
- æ”¯æŒç«–æ’æ–‡æœ¬ã€é‡å æ–‡æœ¬å’Œè£…é¥°å…ƒç´ 
- æ— éœ€æ–‡æœ¬æå–é”™è¯¯çš„ç›´æ¥ç¿»è¯‘

### ğŸ“‹ Prerequisites | å‰ç½®è¦æ±‚

1. **API Key**: You need an API key from one of the supported services:
   - OpenAI (GPT-4o, GPT-4 Vision) - https://platform.openai.com/api-keys
   - Azure OpenAI with vision models
   - Any OpenAI-compatible API service with vision support

2. **API Credits**: Ensure your account has sufficient credits (multimodal calls cost more than text-only)

1. **API å¯†é’¥**ï¼šæ‚¨éœ€è¦æ¥è‡ªä»¥ä¸‹æ”¯æŒæœåŠ¡ä¹‹ä¸€çš„ API å¯†é’¥ï¼š
   - OpenAI (GPT-4oã€GPT-4 Vision) - https://platform.openai.com/api-keys
   - å¸¦æœ‰è§†è§‰æ¨¡å‹çš„ Azure OpenAI
   - ä»»ä½•æ”¯æŒè§†è§‰çš„ OpenAI å…¼å®¹ API æœåŠ¡

2. **API é¢åº¦**ï¼šç¡®ä¿æ‚¨çš„è´¦æˆ·æœ‰è¶³å¤Ÿçš„é¢åº¦ï¼ˆå¤šæ¨¡æ€è°ƒç”¨æ¯”çº¯æ–‡æœ¬è°ƒç”¨æ›´æ˜‚è´µï¼‰

### ğŸš€ Step-by-Step Setup Guide | åˆ†æ­¥è®¾ç½®æŒ‡å—

#### Step 1: Open Settings | ç¬¬ 1 æ­¥ï¼šæ‰“å¼€è®¾ç½®

Press **Alt+G** to open the Translumo settings window.

æŒ‰ **Alt+G** æ‰“å¼€ Translumo è®¾ç½®çª—å£ã€‚

#### Step 2: Select Multimodal Translator | ç¬¬ 2 æ­¥ï¼šé€‰æ‹©å¤šæ¨¡æ€ç¿»è¯‘å™¨

1. Navigate to the **Languages** tab
2. In the **Translator** dropdown, select **Multimodal**
3. A new configuration panel will appear with four fields

1. è½¬åˆ° **Languagesï¼ˆè¯­è¨€ï¼‰** é€‰é¡¹å¡
2. åœ¨ **Translatorï¼ˆç¿»è¯‘å™¨ï¼‰** ä¸‹æ‹‰èœå•ä¸­ï¼Œé€‰æ‹© **Multimodalï¼ˆå¤šæ¨¡æ€ï¼‰**
3. å°†å‡ºç°ä¸€ä¸ªåŒ…å«å››ä¸ªå­—æ®µçš„æ–°é…ç½®é¢æ¿

#### Step 3: Configure API Settings | ç¬¬ 3 æ­¥ï¼šé…ç½® API è®¾ç½®

**For OpenAI (Recommended) | ä½¿ç”¨ OpenAIï¼ˆæ¨èï¼‰ï¼š**

- **Base URL**: `https://api.openai.com/v1/chat/completions` (default, no change needed)
- **API Key**: Enter your OpenAI API key (starts with `sk-...`)
- **Model Name**: `gpt-4o` (recommended) or `gpt-4-vision-preview`
- **Prompt**: Customize based on your target language (see examples below)

**For Azure OpenAI | ä½¿ç”¨ Azure OpenAIï¼š**

- **Base URL**: `https://<your-resource>.openai.azure.com/openai/deployments/<deployment-name>/chat/completions?api-version=2024-02-15-preview`
- **API Key**: Your Azure OpenAI API key
- **Model Name**: Your deployment name
- **Prompt**: Customize based on your target language

**For Other Compatible APIs | ä½¿ç”¨å…¶ä»–å…¼å®¹ APIï¼š**

- **Base URL**: Your service's chat completions endpoint
- **API Key**: Your service's API key
- **Model Name**: Check your service's documentation
- **Prompt**: Customize based on your target language

#### Step 4: Customize the Prompt | ç¬¬ 4 æ­¥ï¼šè‡ªå®šä¹‰æç¤ºè¯

The prompt tells the AI model what to do with the image. Here are examples for different languages:

æç¤ºè¯å‘Šè¯‰ AI æ¨¡å‹å¦‚ä½•å¤„ç†å›¾åƒã€‚ä»¥ä¸‹æ˜¯ä¸åŒè¯­è¨€çš„ç¤ºä¾‹ï¼š

**English to Chinese | è‹±è¯‘ä¸­ï¼š**
```
Translate all text in this image to Chinese. Only output the translated text, no explanations.
```

**Japanese to English | æ—¥è¯‘è‹±ï¼š**
```
Translate all Japanese text in this image to English. Only output the translated text, no explanations.
```

**Chinese to English | ä¸­è¯‘è‹±ï¼š**
```
Translate all Chinese text in this image to English. Only output the translated text, no explanations.
```

**Korean to Chinese | éŸ©è¯‘ä¸­ï¼š**
```
Translate all Korean text in this image to Chinese. Only output the translated text, no explanations.
```

**With Formatting Preservation | ä¿æŒæ ¼å¼ï¼š**
```
Translate all text in this image to Chinese. Maintain the original line breaks and formatting. Only output the translated text.
```

**With Context Explanation | åŒ…å«ä¸Šä¸‹æ–‡è§£é‡Šï¼š**
```
Translate all text in this image to English and briefly explain any cultural references or context.
```

#### Step 5: Select Source Language | ç¬¬ 5 æ­¥ï¼šé€‰æ‹©æºè¯­è¨€

Even though multimodal translation doesn't use OCR, you should still select the **Source Language** that matches your content for proper handling.

å³ä½¿å¤šæ¨¡æ€ç¿»è¯‘ä¸ä½¿ç”¨ OCRï¼Œæ‚¨ä»åº”é€‰æ‹©ä¸å†…å®¹åŒ¹é…çš„**æºè¯­è¨€**ä»¥ä¾¿æ­£ç¡®å¤„ç†ã€‚

#### Step 6: Define Capture Area | ç¬¬ 6 æ­¥ï¼šå®šä¹‰æ•è·åŒºåŸŸ

1. Press **Alt+Q**
2. Click and drag to select the area you want to translate
3. **Tip**: Smaller capture areas = lower API costs and faster processing

1. æŒ‰ **Alt+Q**
2. ç‚¹å‡»å¹¶æ‹–åŠ¨ä»¥é€‰æ‹©è¦ç¿»è¯‘çš„åŒºåŸŸ
3. **æç¤º**ï¼šè¾ƒå°çš„æ•è·åŒºåŸŸ = æ›´ä½çš„ API æˆæœ¬å’Œæ›´å¿«çš„å¤„ç†é€Ÿåº¦

#### Step 7: Start Translation | ç¬¬ 7 æ­¥ï¼šå¼€å§‹ç¿»è¯‘

Press **~** (tilde key) to start the translation. The captured image will be sent to the multimodal API, and the translation will appear in the overlay window.

æŒ‰ **~**ï¼ˆæ³¢æµªå·é”®ï¼‰å¼€å§‹ç¿»è¯‘ã€‚æ•è·çš„å›¾åƒå°†è¢«å‘é€åˆ°å¤šæ¨¡æ€ APIï¼Œç¿»è¯‘ç»“æœå°†æ˜¾ç¤ºåœ¨è¦†ç›–çª—å£ä¸­ã€‚

### ğŸ’¡ Tips and Best Practices | æç¤ºå’Œæœ€ä½³å®è·µ

1. **Start with Small Areas**: Test with small capture areas first to verify your setup and minimize costs
   
   **ä»å°åŒºåŸŸå¼€å§‹**ï¼šé¦–å…ˆä½¿ç”¨å°çš„æ•è·åŒºåŸŸè¿›è¡Œæµ‹è¯•ï¼Œä»¥éªŒè¯è®¾ç½®å¹¶é™ä½æˆæœ¬

2. **Optimize Prompts**: Experiment with different prompts to get better results for your specific use case
   
   **ä¼˜åŒ–æç¤ºè¯**ï¼šå°è¯•ä¸åŒçš„æç¤ºè¯ï¼Œä¸ºæ‚¨çš„ç‰¹å®šç”¨ä¾‹è·å¾—æ›´å¥½çš„ç»“æœ

3. **Use Proxy if Needed**: If you experience rate limiting, configure proxies under **Languages â†’ Proxy tab**
   
   **å¿…è¦æ—¶ä½¿ç”¨ä»£ç†**ï¼šå¦‚æœé‡åˆ°é€Ÿç‡é™åˆ¶ï¼Œè¯·åœ¨ **Languages â†’ Proxy** é€‰é¡¹å¡ä¸‹é…ç½®ä»£ç†

4. **Monitor API Usage**: Keep track of your API usage and costs through your provider's dashboard
   
   **ç›‘æ§ API ä½¿ç”¨æƒ…å†µ**ï¼šé€šè¿‡æä¾›å•†çš„ä»ªè¡¨æ¿è·Ÿè¸ªæ‚¨çš„ API ä½¿ç”¨æƒ…å†µå’Œæˆæœ¬

5. **Fallback Option**: Keep traditional translators (like DeepL) configured so you can switch when needed
   
   **å¤‡ç”¨é€‰é¡¹**ï¼šä¿æŒä¼ ç»Ÿç¿»è¯‘å™¨ï¼ˆå¦‚ DeepLï¼‰é…ç½®ï¼Œä»¥ä¾¿åœ¨éœ€è¦æ—¶åˆ‡æ¢

### âš™ï¸ Advanced Configuration | é«˜çº§é…ç½®

**Using Local Models | ä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼š**

If you're running a local vision model (e.g., through LM Studio or LocalAI):

å¦‚æœæ‚¨æ­£åœ¨è¿è¡Œæœ¬åœ°è§†è§‰æ¨¡å‹ï¼ˆä¾‹å¦‚é€šè¿‡ LM Studio æˆ– LocalAIï¼‰ï¼š

- **Base URL**: `http://localhost:1234/v1/chat/completions` (or your local server URL)
- **API Key**: May not be required (use `none` or any value)
- **Model Name**: Your local model name
- **Prompt**: Standard translation prompt

**Custom Model Parameters | è‡ªå®šä¹‰æ¨¡å‹å‚æ•°ï¼š**

Currently, the implementation uses default parameters. If you need custom parameters (temperature, max_tokens, etc.), you may need to modify the API endpoint or use a proxy service that allows parameter injection.

å½“å‰å®ç°ä½¿ç”¨é»˜è®¤å‚æ•°ã€‚å¦‚æœéœ€è¦è‡ªå®šä¹‰å‚æ•°ï¼ˆtemperatureã€max_tokens ç­‰ï¼‰ï¼Œæ‚¨å¯èƒ½éœ€è¦ä¿®æ”¹ API ç«¯ç‚¹æˆ–ä½¿ç”¨å…è®¸å‚æ•°æ³¨å…¥çš„ä»£ç†æœåŠ¡ã€‚

### ğŸ”§ Troubleshooting | æ•…éšœæ’é™¤

**Problem: "Multimodal API error: Unauthorized"**
- Solution: Check that your API key is correct and has not expired
- è§£å†³æ–¹æ¡ˆï¼šæ£€æŸ¥æ‚¨çš„ API å¯†é’¥æ˜¯å¦æ­£ç¡®ä¸”æœªè¿‡æœŸ

**Problem: "Multimodal API error: Model not found"**
- Solution: Verify the model name is correct for your service
- è§£å†³æ–¹æ¡ˆï¼šéªŒè¯æ¨¡å‹åç§°å¯¹æ‚¨çš„æœåŠ¡æ˜¯å¦æ­£ç¡®

**Problem: No translation appears**
- Solution: Check your internet connection, API credits, and console logs for detailed errors
- è§£å†³æ–¹æ¡ˆï¼šæ£€æŸ¥æ‚¨çš„äº’è”ç½‘è¿æ¥ã€API é¢åº¦å’Œæ§åˆ¶å°æ—¥å¿—ä»¥è·å–è¯¦ç»†é”™è¯¯

**Problem: Translation is too slow**
- Solution: Use smaller capture areas, or switch to a faster model (e.g., gpt-4o-mini if available)
- è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨è¾ƒå°çš„æ•è·åŒºåŸŸï¼Œæˆ–åˆ‡æ¢åˆ°æ›´å¿«çš„æ¨¡å‹ï¼ˆä¾‹å¦‚ gpt-4o-miniï¼Œå¦‚æœå¯ç”¨ï¼‰

**Problem: High API costs**
- Solution: Use traditional OCR+translation for bulk content, reserve multimodal for difficult text
- è§£å†³æ–¹æ¡ˆï¼šå¯¹äºå¤§é‡å†…å®¹ä½¿ç”¨ä¼ ç»Ÿçš„ OCR+ç¿»è¯‘ï¼Œä¸ºå›°éš¾æ–‡æœ¬ä¿ç•™å¤šæ¨¡æ€ç¿»è¯‘

### ğŸ“Š Cost Comparison | æˆæœ¬æ¯”è¾ƒ

**Traditional Translation (OCR + DeepL/Google):**
- Nearly free for unlimited use
- å‡ ä¹å…è´¹æ— é™ä½¿ç”¨

**Multimodal Translation (GPT-4o):**
- ~$0.002-0.01 per image (varies by image size and model)
- æ¯å¼ å›¾ç‰‡çº¦ $0.002-0.01ï¼ˆå› å›¾ç‰‡å¤§å°å’Œæ¨¡å‹è€Œå¼‚ï¼‰

**Recommendation**: Use multimodal translation for challenging content where OCR fails, and traditional translation for regular text.

**å»ºè®®**ï¼šå¯¹ OCR å¤±è´¥çš„æŒ‘æˆ˜æ€§å†…å®¹ä½¿ç”¨å¤šæ¨¡æ€ç¿»è¯‘ï¼Œå¯¹å¸¸è§„æ–‡æœ¬ä½¿ç”¨ä¼ ç»Ÿç¿»è¯‘ã€‚

### ğŸ“š Additional Resources | å…¶ä»–èµ„æº

- **Full Documentation**: See [docs/MULTIMODAL.md](docs/MULTIMODAL.md) for technical details
- **Implementation Summary**: See [IMPLEMENTATION_SUMMARY.md](IMPLEMENTATION_SUMMARY.md) for development details
- **Original Repository**: https://github.com/ramjke/Translumo

- **å®Œæ•´æ–‡æ¡£**ï¼šæŸ¥çœ‹ [docs/MULTIMODAL.md](docs/MULTIMODAL.md) äº†è§£æŠ€æœ¯ç»†èŠ‚
- **å®ç°æ‘˜è¦**ï¼šæŸ¥çœ‹ [IMPLEMENTATION_SUMMARY.md](IMPLEMENTATION_SUMMARY.md) äº†è§£å¼€å‘è¯¦æƒ…
- **åŸå§‹ä»“åº“**ï¼šhttps://github.com/ramjke/Translumo

## Build

*Visual Studio 2022 and .NET 8 SDK are required.*

1. Clone this fork repository:

    ```bash
    git clone https://github.com/mimomi666/Translumo.git
    ```

   Or clone the original repository:

    ```bash
    git clone https://github.com/ramjke/Translumo.git
    ```

> Note: During the build, **binaries_extract.bat** will automatically download and extract models and Python binaries (~400 MB) to the target output directory.

## Creating Releases

**For Maintainers**: This repository includes automated GitHub Actions workflows to build and publish releases.

ğŸ“– **Quick Start**: See [QUICKSTART_RELEASE.md](QUICKSTART_RELEASE.md) or [QUICKSTART_RELEASE_CN.md](QUICKSTART_RELEASE_CN.md) (ä¸­æ–‡ç‰ˆ)

ğŸ“š **Detailed Guide**: See [RELEASE_GUIDE.md](RELEASE_GUIDE.md) for comprehensive instructions

**Easy Method**: 
1. Go to [Actions](../../actions) â†’ "Build and Release"
2. Click "Run workflow"
3. Enter version number (e.g., `1.0.2`)
4. The workflow will automatically build, package, and create a GitHub release

**Tag Method**: 
```bash
git tag v1.0.2
git push origin v1.0.2
```

The release package will include everything needed to run Translumo, including the .NET runtime, OCR models, and Python dependencies (~500-600 MB total).

## Credits

- [Material Design In XAML Toolkit](https://github.com/MaterialDesignInXAML/MaterialDesignInXamlToolkit)  
- [Tesseract .NET wrapper](https://github.com/charlesw/tesseract)  
- [OpenCvSharp](https://github.com/shimat/opencvsharp)  
- [Python.NET](https://github.com/pythonnet/pythonnet)  
- [EasyOCR](https://github.com/JaidedAI/EasyOCR)  
- [Silero TTS](https://github.com/snakers4/silero-models)  

## Alternative Solutions

- [Lookupper](https://lookupper.com) â€” on-screen dictionary and translator for language learning.
- [ScreTran](https://github.com/PavlikBender/ScreTran) â€” simple screen translator.
- [ScreenTranslator](https://github.com/OneMoreGres/ScreenTranslator) - screen capture, OCR and translation tool.

